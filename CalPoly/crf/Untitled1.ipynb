{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "import spacy\n",
    "import re\n",
    "import sys\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "\n",
    "\n",
    "def get_data(file):\n",
    "    data = []\n",
    "    with open(file, \"r\", encoding='utf8') as f:\n",
    "        \"\"\"\n",
    "        input: \"<tag>w w w w.\"\n",
    "        output: list of ([w pos y])\n",
    "        \"\"\"\n",
    "        for course in f.readlines(): \n",
    "            sentences = re.split('\\<\\/\\w+\\>', course)\n",
    "            c_data = []\n",
    "            for sentence in sentences:\n",
    "                if not sentence.isspace():\n",
    "                    try:\n",
    "                        match = re.match('\\<\\w+\\>', sentence.strip())\n",
    "                        chunk_name = match.group()\n",
    "                        sentence = sentence[:match.start()]+ sentence[match.end():]\n",
    "                        docs = nlp(sentence)\n",
    "                        for token in docs:\n",
    "                            if token.text != '>':\n",
    "                                c_data.append((token.text, token.tag_, chunk_name))  \n",
    "                    except:\n",
    "                        continue\n",
    "            data.append(c_data)\n",
    "        return data\n",
    "\n",
    "\n",
    "def word2features(doc, i):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        doc ->list(list[string]): tuples of (words, pos, label)\n",
    "    output:\n",
    "        features -> list(string): features of a single word, gotten from last and next word\n",
    "    \"\"\"\n",
    "    word = doc[i][0] #word\n",
    "    postag = doc[i][1] #tag\n",
    "    features = [\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'word.isdot=%s' % isdot(word),\n",
    "        'word.length=' + str(len(word)),\n",
    "        'postag=%s' % postag,\n",
    "        'postag[:2]=%s' % postag[:2]\n",
    "    ]\n",
    "    \n",
    "    if i > 0:\n",
    "        prev_word = doc[i-1][0]\n",
    "        prev_postag = doc[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + prev_word.lower(),\n",
    "            '-1:word.isupper=%s' % prev_word.isupper(),\n",
    "            '-1:word.istitle=%s' % prev_word.istitle(),\n",
    "            '-1:word.isdigit=%s' % prev_word.isdigit(),\n",
    "            '-1:word.isdot=%s' % isdot(prev_word),\n",
    "            '-1:word.length=' + str(len(prev_word)),\n",
    "            '-1:postag=%s' % prev_postag,\n",
    "            '-1:postag[:2]=%s' % prev_postag[:2], \n",
    "            'last|word=%s|%s' %(prev_word,word)\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i > 1:\n",
    "        prev_word = doc[i-2][0]\n",
    "        prev_postag = doc[i-2][1]\n",
    "        features.extend([\n",
    "            '-2:word.lower=' + prev_word.lower(),\n",
    "            '-2:word.length=' + str(len(prev_word)),\n",
    "            '-2:word.isupper=%s' % prev_word.isupper(),\n",
    "            '-2:word.istitle=%s' % prev_word.istitle(),\n",
    "            '-2:word.isdigit=%s' % prev_word.isdigit(),\n",
    "            '-2:word.isdot=%s' % isdot(prev_word),\n",
    "            '-2:postag=%s' % prev_postag,\n",
    "            '-2:postag[:2]=%s' % prev_postag[:2]\n",
    "        ])\n",
    "\n",
    "    if i < len(doc)-1:\n",
    "        next_word = doc[i+1][0]\n",
    "        next_postag = doc[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + next_word.lower(),\n",
    "            '+1:word.isupper=%s' % next_word.isupper(),\n",
    "            '+1:word.istitle=%s' % next_word.istitle(),\n",
    "            '+1:word.isdigit=%s' % next_word.isdigit(),\n",
    "            '+1:word.isdot=%s' % isdot(next_word),\n",
    "            '+1:postag=%s' % next_postag,\n",
    "            '+1:word.length=' + str(len(next_word)),\n",
    "            '+1:postag[:2]=%s' % next_postag[:2], \n",
    "            'word|next=%s|%s' %(word,next_word), \n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "        \n",
    "    if i < len(doc)-2:\n",
    "        next_word = doc[i+2][0]\n",
    "        next_postag = doc[i+2][1]\n",
    "        features.extend([\n",
    "            '+2:word.lower=' + next_word.lower(),\n",
    "            '+2:word.length=' + str(len(next_word)),\n",
    "            '+2:word.isupper=%s' % next_word.isupper(),\n",
    "            '+2:word.istitle=%s' % next_word.istitle(),\n",
    "            '+2:word.isdigit=%s' % next_word.isdigit(),\n",
    "            '+2:word.isdot=%s' % isdot(next_word),\n",
    "            '+2:postag=%s' % next_postag,\n",
    "            '+2:postag[:2]=%s' % next_postag[:2]\n",
    "        ])\n",
    "    \n",
    "\n",
    "    return features\n",
    "\n",
    "def isdot(word):\n",
    "    return True if '.' in word else False\n",
    "\n",
    "def get_features(doc):\n",
    "    \"\"\"\n",
    "    input: doc\n",
    "    output: \n",
    "        feature list: list of features by each word\n",
    "    \"\"\"\n",
    "    return [word2features(doc,i) for i in range(len(doc))] \n",
    "\n",
    "def get_labels(doc):\n",
    "    return [label for (token, postag, label) in doc]\n",
    "\n",
    "\n",
    "train_data = get_data('train-calpoly_tag.txt')\n",
    "# test_data = get_data('test-calpoly-tag-s.txt')\n",
    "X_train = [get_features(course_doc) for course_doc in train_data]\n",
    "y_train = [get_labels(course_doc) for course_doc in train_data]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# X_test = [get_features(course_doc) for course_doc in test_data]\n",
    "# Y_test = [get_labels(course_doc) for course_doc in test_data]\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "trainer.set_params({\n",
    "        'c1': 0.1,  \n",
    "        'c2': 0.01, \n",
    "        'max_iterations': 10\n",
    "    })    \n",
    "trainer.train('calpoly.model')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ucla.model')\n",
    "predict = [tagger.tag(xseq) for xseq in X_test] \n",
    "\n",
    "# Y_test = [train.extract_label(course) for course in data_test]\n",
    "tp = 0 \n",
    "tn = 0 \n",
    "fp = 0 \n",
    "fn = 0 \n",
    "for j in range(len(Y_test)):\n",
    "    for i in range(1,len(Y_test[j])):\n",
    "        if Y_test[j][i] == Y_test[j][i-1]: \n",
    "            test_result = 'N' \n",
    "        else:\n",
    "            test_result = 'P'\n",
    "        if predict[j][i] != predict[j][i-1] : #P\n",
    "            if test_result == 'P':\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1  \n",
    "        else:\n",
    "            if test_result == 'N':\n",
    "                if data_test[j][i-1][0] == '.':\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                fn += 1 \n",
    "print(tp, fp+fn)\n",
    "\n",
    "\n",
    "precision = float(tp)/(tp+fp)\n",
    "recall = float(tp)/(tp+fn)\n",
    "f = 2*precision*recall / (precision + recall)\n",
    "print('Precision = %f\\nRecall = %f\\nF1 score = %f' %(precision, recall, f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
